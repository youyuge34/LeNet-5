{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import LeNet5_infernece\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1. 定义神经网络相关的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE_BASE = 0.01\n",
    "LEARNING_RATE_DECAY = 0.99\n",
    "REGULARIZATION_RATE = 0.0001\n",
    "TRAINING_STEPS = 200\n",
    "MOVING_AVERAGE_DECAY = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 定义训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mnist):\n",
    "    # 定义输出为4维矩阵的placeholder\n",
    "    x = tf.placeholder(tf.float32, [\n",
    "            None,\n",
    "            LeNet5_infernece.IMAGE_SIZE,\n",
    "            LeNet5_infernece.IMAGE_SIZE,\n",
    "            LeNet5_infernece.NUM_CHANNELS],\n",
    "        name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None, LeNet5_infernece.OUTPUT_NODE], name='y-input')\n",
    "    \n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "    y = LeNet5_infernece.inference(x,False,regularizer)\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "    # 定义损失函数、学习率、滑动平均操作以及训练过程。\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    loss = cross_entropy_mean + tf.add_n(tf.get_collection('losses'))\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        LEARNING_RATE_BASE,\n",
    "        global_step,\n",
    "        mnist.train.num_examples / BATCH_SIZE, LEARNING_RATE_DECAY,\n",
    "        staircase=True)\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    with tf.control_dependencies([train_step, variables_averages_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "        \n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "    # 初始化TensorFlow持久化类。\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        tf.global_variables_initializer().run()\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "\n",
    "            reshaped_xs = np.reshape(xs, (\n",
    "                BATCH_SIZE,\n",
    "                LeNet5_infernece.IMAGE_SIZE,\n",
    "                LeNet5_infernece.IMAGE_SIZE,\n",
    "                LeNet5_infernece.NUM_CHANNELS))\n",
    "            _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict={x: reshaped_xs, y_: ys})\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(\"After %d training step(s), loss on training batch is %g.\" % (step, loss_value))\n",
    "        \n",
    "        #dev验证集进行验证测试\n",
    "        reshaped_xs = np.reshape(mnist.validation.images, (\n",
    "                -1,\n",
    "                LeNet5_infernece.IMAGE_SIZE,\n",
    "                LeNet5_infernece.IMAGE_SIZE,\n",
    "                LeNet5_infernece.NUM_CHANNELS))\n",
    "        validate_feed = {x: reshaped_xs, y_: mnist.validation.labels}\n",
    "        print sess.run(accuracy,feed_dict = validate_feed)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 主程序入口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../../datasets/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../../datasets/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../../datasets/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../../datasets/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "After 1 training step(s), loss on training batch is 4.51752.\n",
      "After 11 training step(s), loss on training batch is 2.13127.\n",
      "After 21 training step(s), loss on training batch is 1.90628.\n",
      "After 31 training step(s), loss on training batch is 1.47134.\n",
      "After 41 training step(s), loss on training batch is 1.2439.\n",
      "After 51 training step(s), loss on training batch is 1.1529.\n",
      "After 61 training step(s), loss on training batch is 1.08565.\n",
      "After 71 training step(s), loss on training batch is 1.17094.\n",
      "After 81 training step(s), loss on training batch is 1.13228.\n",
      "After 91 training step(s), loss on training batch is 1.08917.\n",
      "After 101 training step(s), loss on training batch is 0.996232.\n",
      "After 111 training step(s), loss on training batch is 1.06707.\n",
      "After 121 training step(s), loss on training batch is 0.897435.\n",
      "After 131 training step(s), loss on training batch is 1.02432.\n",
      "After 141 training step(s), loss on training batch is 0.852663.\n",
      "After 151 training step(s), loss on training batch is 0.955707.\n",
      "After 161 training step(s), loss on training batch is 0.908039.\n",
      "After 171 training step(s), loss on training batch is 1.02893.\n",
      "After 181 training step(s), loss on training batch is 0.871466.\n",
      "After 191 training step(s), loss on training batch is 0.920876.\n",
      "0.9262\n"
     ]
    }
   ],
   "source": [
    "def main(argv=None):\n",
    "    #改成你自己的mnist数据文件夹目录\n",
    "    mnist = input_data.read_data_sets(\"../../../datasets/MNIST_data\", one_hot=True)\n",
    "    train(mnist)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
